{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bLGc9XcDNqhi"
   },
   "source": [
    "<a id=\"tercero\"></a>\n",
    "## 3. Entendimiento de imágenes de personas\n",
    "\n",
    "El problema de inferir ciertas características de una persona a través de una foto de ella puede resultar bastante dificil incluso para nosotros, como por ejemplo de qué país es, la emoción que expresa, la edad que tiene, o el género. La automatización de este proceso para que máquinas logren identificar ciertas características de una persona puede ser algo crucial para el futuro desarrollo de Inteligencia Artificial.\n",
    "\n",
    "\n",
    "<img src=\"https://i.imgur.com/6B072GE.jpg\" width=\"60%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "En esta actividad trabajaremos con unos datos (imágenes) con la tarea de predecir la **edad** (*target value*) de la persona en la imagen. Los datos con corresponden a 3640 imágenes de Flickr de rostros de personas, pero, debido a que trabajamos con redes *feed forward*, se trabajará con representaciones de características extraídas. Para ésto necesitará descargar los datos del siguiente __[link](http://chenlab.ece.cornell.edu/people/Andy/ImagesOfGroups.html)__ en el extracto de *ageGenderClassification* o a través de la consola Unix.\n",
    "```\n",
    "wget http://chenlab.ece.cornell.edu/projects/ImagesOfGroups/ageGenderClassification.zip\n",
    "```\n",
    "\n",
    "Se trabajará con archivos *.mat* que pueden ser cargados de la siguiente manera:\n",
    "```python\n",
    "import scipy.io as sio\n",
    "sio.loadmat(\"file.mat\")\n",
    "```\n",
    "\n",
    "Para descripción sobre las columnas están en el archivo readme a través del siguiente __[link](http://chenlab.ece.cornell.edu/projects/ImagesOfGroups/README.txt)__ o a través de la consola Unix:\n",
    "```\n",
    "wget http://chenlab.ece.cornell.edu/projects/ImagesOfGroups/README.txt\n",
    "```\n",
    "\n",
    "\n",
    "> a) Cargue los datos dos dataset de entrenamiento y de pruebas ¿Cuántos datos hay en cada conjunto?\n",
    "```python\n",
    "import scipy.io as sio\n",
    "mat_train = sio.loadmat(\"./eventrain.mat\")\n",
    "mat_test = sio.loadmat(\"./eventest.mat\")\n",
    "data_train= mat_train[\"trcoll\"][0][0]\n",
    "data_test= mat_test[\"tecoll\"][0][0]\n",
    "```\n",
    "\n",
    "> b) Eliga cuál representación utilizará para trabajar los datos y entregárselos como *input* al modelo neuronal denso. Además extraiga las etiquetas del problema. Describa los datos utilziados.\n",
    "```python\n",
    "genFeat = data[0]  #it can be used as representation: contextual features\n",
    "ageClass = data[1] #target\n",
    "ffcoefs = data[3]   #it can be used as representation: fisherface space\n",
    "faceGist = data[4]  #it can be used as representation\n",
    "```\n",
    "\n",
    "> c) Defina y entrene una modelo de red neuronal *feed forward* para la inferencia de la edad de la persona a través de la representación escogida. Intente llegar a un *mse* menor a 100 en el conjunto de pruebas. Recuerde que **NO** puede seleccionar modelos a través del conjunto de pruebas. Visualice sus resultados si estima conveniente.\n",
    "\n",
    "\n",
    "*Nota: Puede notar que la cantidad de edades presentes en el problema son pocas (1,  5, 10, 16, 28, 51 o 75 años), por lo que puede tratar al problema así como de regresión o clasificación (considerando cada edad como una clase)*\n",
    "\n",
    "\n",
    "#### Ayuda:\n",
    "> Para problemas de clasificación de múltiples clases es necesario transformar las etiquetas categóricas en *one hot vector*, donde cada columna del vector representará una categoría. Por ejemplo, si existen tres categorías (perro, gato, ratón), la categoría perro puede ser codificada como [1,0,0], y la categoría ratón puede ser codificada como [0,0,1]. Para ésto la librería *keras* nos ayuda:\n",
    "\n",
    "```python\n",
    "import keras\n",
    "y_onehot = keras.utils.to_categorical(y_train,num_classes=edades_distintas)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "mat_train = sio.loadmat(\"./eventrain.mat\")\n",
    "mat_test = sio.loadmat(\"./eventest.mat\")\n",
    "data_train= mat_train[\"trcoll\"][0][0]\n",
    "data_test= mat_test[\"tecoll\"][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.20000000e+01,  3.40000000e+01,  3.00000000e+00, ...,\n",
       "         1.05718040e+02,  1.87811527e+01,  3.06854736e+02],\n",
       "       [ 6.00000000e+01,  1.20000000e+01,  1.00000000e+00, ...,\n",
       "         1.51088806e+02, -3.41068054e+02,  9.30533905e+01],\n",
       "       [ 2.90000000e+01,  3.50000000e+01,  2.00000000e+00, ...,\n",
       "         1.51514084e+02,  1.57356903e+02,  2.35412140e+02],\n",
       "       ...,\n",
       "       [ 6.30000000e+01,  3.90000000e+01,  2.00000000e+00, ...,\n",
       "         1.80594995e+03,  7.68546997e+02, -2.29365768e+02],\n",
       "       [ 5.70000000e+01,  8.10000000e+01,  1.00000000e+00, ...,\n",
       "        -1.05423975e+03, -1.09025903e+03, -1.49180969e+02],\n",
       "       [ 3.00000000e+01,  6.10000000e+01,  1.00000000e+00, ...,\n",
       "         5.14633118e+02, -1.44830612e+02, -1.82602676e+02]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 1)\n",
      "[[104 108 112 ...  83  80  82]\n",
      " [237 197 118 ... 186 219 226]\n",
      " [ 66  66  55 ...  82  77  65]\n",
      " ...\n",
      " [ 50  52  36 ...  65  70  70]\n",
      " [ 63  48  62 ... 148 153 157]\n",
      " [124 127 131 ...  89 134 182]]\n"
     ]
    }
   ],
   "source": [
    "genFeat = data_train[0]  #it can be used as representation: contextual features\n",
    "ageClass = data_train[1] #target\n",
    "ffcoefs = data_train[3]   #it can be used as representation: fisherface space\n",
    "faceGist = data_train[4]  #it can be used as representation\n",
    "print(data_train[2].shape)\n",
    "print(data_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1101.0"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((targets.astype(int) - 5)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import numpy as np\n",
    "    data = np.concatenate((genFeat,ffcoefs,faceGist),axis=1)\n",
    "    targets = ageClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Input\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD, Adam, RMSprop, Adagrad, Adadelta\n",
    "from keras.regularizers import l1,l2\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "mat_train = sio.loadmat(\"./eventrain.mat\")\n",
    "mat_test = sio.loadmat(\"./eventest.mat\")\n",
    "data_train= mat_train[\"trcoll\"][0][0]\n",
    "data_test= mat_test[\"tecoll\"][0][0]\n",
    "\n",
    "genFeat = data_train[0]  #it can be used as representation: contextual features\n",
    "ageClass = data_train[1] #target\n",
    "ffcoefs = data_train[3]   #it can be used as representation: fisherface space\n",
    "faceGist = data_train[4]  #it can be used as representation\n",
    "\n",
    " \n",
    "data = np.concatenate((genFeat,ffcoefs,faceGist),axis=1)\n",
    "targets = ageClass.reshape(-1)\n",
    "target_to_class = {'1':0,'5':1,'10':2,'16':3,'28':4,'51':5,'75':6}\n",
    "classes = np.zeros(len(targets))\n",
    "targets_vector = [1,5,10,16,28,51,75]\n",
    "\n",
    "for i in range(len(targets)):\n",
    "    classes[i] = target_to_class[str(targets[i])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(targets[test_index],bins= 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = open('pregunta3_results/results.txt', 'r')\n",
    "results = []\n",
    "for row in results_file:\n",
    "    results.append(row.replace('t_u','t--u').replace('e_u','e--u').strip('\\n').split('_'))\n",
    "    \n",
    "results_file_dropout = open('pregunta3_results/dropout_results.txt', 'r')\n",
    "results_dropout = []\n",
    "for row in results_file_dropout:\n",
    "    results_dropout.append(row.replace('t_u','t--u').replace('e_u','e--u').strip('\\n').split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results.columns = ['n_layers', 'neurons','activation','initializer','learning_rate','epochs','mse','val_mse','accuracy']\n",
    "results_dropout = pd.DataFrame(results_dropout)\n",
    "results_dropout.columns = ['n_layers', 'neurons','activation','initializer','learning_rate','epochs','mse','val_mse','accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      1\n",
       "1                     10\n",
       "2                   relu\n",
       "3        glorot--uniform\n",
       "4                 0.0001\n",
       "5                   1000\n",
       "6     1005.8607142857143\n",
       "7                1007.76\n",
       "8    0.13428571428571429\n",
       "dtype: object"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_numeric(results, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[['n_layers', 'neurons','learning_rate','epochs','mse','val_mse','accuracy']] = \\\n",
    "results[['n_layers', 'neurons','learning_rate','epochs','mse','val_mse','accuracy']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['n_layers' 'neurons' 'learning_rate' 'epochs' 'mse' 'val_mse' 'accuracy'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-348-951ae4b05ceb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mresults_dropout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n_layers'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'neurons'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'learning_rate'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'val_mse'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresults_dropout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n_layers'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'neurons'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'learning_rate'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'val_mse'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\python36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2680\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2681\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2682\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2683\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\python36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2724\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2725\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2726\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2727\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\python36\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1325\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[1;32m-> 1327\u001b[1;33m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['n_layers' 'neurons' 'learning_rate' 'epochs' 'mse' 'val_mse' 'accuracy'] not in index\""
     ]
    }
   ],
   "source": [
    "results_dropout[['n_layers', 'neurons','learning_rate','epochs','mse','val_mse','accuracy']] = \\\n",
    "results_dropout[['n_layers', 'neurons','learning_rate','epochs','mse','val_mse','accuracy']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: 0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-307-211ed615585c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'initializer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\python36\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Column not found: {key}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Column not found: 0'"
     ]
    }
   ],
   "source": [
    "results['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Enunciado.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
