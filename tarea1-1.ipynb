{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84-hf1CuNqhZ"
   },
   "source": [
    "<a id=\"primero\"></a>\n",
    "## 1. Predicción de Entalpía de Atomización\n",
    "\n",
    "\n",
    "Las simulaciones de propiedades moleculares son computacionalmente costosas y requieren de un arduo trabajo científico. El objetivo de esta sección corresponde a la utilización de métodos de aprendizaje automático supervisado (Redes Neuronales Artificiales) para predecir propiedades moleculares, en este caso la Energía de Atomización o Entalpía de Atomización, a partir de una base de datos de simulaciones obtenida mediante __[Quantum Espresso](http://www.quantum-espresso.org/)__. Si esto se lograse hacer con gran precisión, se abrirían muchas posibilidades en el diseño computacional y el descubrimiento de nuevas moléculas, compuestos y fármacos.\n",
    "\n",
    "<img src=\"https://pubs.rsc.org/services/images/RSCpubs.ePlatform.Service.FreeContent.ImageService.svc/ImageService/Articleimage/2012/NR/c2nr11543c/c2nr11543c-f4.gif\" title=\"Title text\" width=\"40%\"/>\n",
    "\n",
    "\n",
    "La **entalpía de atomización** es la cantidad de variación de entalpía cuando los enlaces de un compuesto se rompen y los componentes se reducen a átomos individuales. Tal como se ha indicado, su tarea es la de predecir dicho nivel a partir de los atributos enunciados en el dataset puesto a vuestra disposición en *moodle*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84-hf1CuNqhZ"
   },
   "source": [
    "---\n",
    "a) Construya un *dataframe* con los datos a analizar y descríbalo brevemete. Además, realice la división de éste en los conjuntos de entrenamiento, validación y testeo correspondientes. Comente por qué se deben eliminar ciertas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "84-hf1CuNqhZ"
   },
   "outputs": [],
   "source": [
    "datos = pd.read_csv(\"roboBohr.csv\")\n",
    "print(\"datos.shape:\",datos.shape)\n",
    "datos.info()\n",
    "datos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.drop(columns=['Unnamed: 0','pubchem_id'],axis=1,inplace=True)\n",
    "total = len(datos)\n",
    "df_trai = datos[:int(0.6*total)]                       #60% de los datos\n",
    "df_vali = datos[int(0.6*total):int(0.85*total)]        #25% de los datos\n",
    "df_test = datos[int(0.85*total)::]                     #15% restante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna `Unnamed: 0` representa el id del compuesto dentro del dataset, y `pubchem_id` parece ser un id general para identificar el compuesto. Ambas columnas se remueven porque la asignación de estos índices es arbitraria y su valor no debería estar relacionado con el resultado que debe entregar nuestro modelo (la Entalpía de Atomización, correspondiente a la columna `Eat`). Aunque el modelo debería detectar que no hay correlación entre `Eat` y estos atributos, es mejor removerlos para no *confundir* el aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84-hf1CuNqhZ"
   },
   "source": [
    "---\n",
    "a.1) Una buena práctica es la de normalizar los datos antes de trabajar con el modelo. **Explique por qué se aconseja dicho preprocesamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "84-hf1CuNqhZ"
   },
   "outputs": [],
   "source": [
    "# Get scaler and scale data\n",
    "scaler = StandardScaler().fit(df_trai)\n",
    "X_trai_scaled = pd.DataFrame(scaler.transform(df_trai),columns=df_trai.columns)\n",
    "X_vali_scaled = pd.DataFrame(scaler.transform(df_vali),columns=df_vali.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(df_test),columns=df_test.columns)\n",
    "# Get targets\n",
    "y_trai = df_trai.pop('Eat').values.reshape(-1,1)\n",
    "y_vali = df_vali.pop('Eat').values.reshape(-1,1)\n",
    "y_test = df_test.pop('Eat').values.reshape(-1,1)\n",
    "# Remove targets from attributes\n",
    "X_trai_scaled.drop(columns=['Eat'],axis=1,inplace=True)\n",
    "X_vali_scaled.drop(columns=['Eat'],axis=1,inplace=True)\n",
    "X_test_scaled.drop(columns=['Eat'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muchos modelos de aprendizaje son suceptibles a la escala de los atributos, por ese motivo, atributos con órdenes de magnitud mayores pueden afectar más a los mismos.\n",
    "Para hacer el aprendizaje independiente de las unidades de medición en que se presentan estos atributos y evitar un bias del aprendizaje hacia unos por sobre otros, es que se normalizan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84-hf1CuNqhZ"
   },
   "source": [
    "---\n",
    "b) Muestre en un gráfico el error cuadrático (MSE) para el conjunto de entrenamiento y de pruebas vs número de *epochs* de entrenamiento, para una red *feedforward* de 3 capas, con 256 unidades ocultas y función de activación sigmoidal. Entrene la red usando gradiente descendente estocástico con tasa de aprendizaje (learning rate) 0.01 y 250 epochs de entrenamiento, en el conjunto de entrenamiento y de validación. Comente. Si observara divergencia durante el entrenamiento, determine si esto ocurre para cada repetición del experimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "84-hf1CuNqhZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create model:\n",
    "def create_model(activation='sigmoid',initializer='uniform',lr=0.01,decay=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=X_trai_scaled.shape[1],\n",
    "                    kernel_initializer=initializer,activation=activation))\n",
    "    model.add(Dense(256,kernel_initializer=initializer,activation=activation))\n",
    "    model.add(Dense(256,kernel_initializer=initializer,activation=activation))\n",
    "    model.add(Dense(1, kernel_initializer=initializer,activation=\"linear\"))\n",
    "\n",
    "    model.compile(optimizer=SGD(lr=lr,decay=decay),loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color(i,total):\n",
    "    if i<total//2:\n",
    "        return (2.0*i/float(total),0.0,0.0)\n",
    "    else:\n",
    "        return (1.0,2.0*(i-total//2)/float(total),0.0)\n",
    "\n",
    "class PlotErrors(keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self,text=None,labels=None):\n",
    "        self.trai_err = []\n",
    "        self.vali_err = []\n",
    "        self.labels = labels\n",
    "        self.trai_title = \"Training error v/s epoch\"\n",
    "        self.vali_title = \"Validaton error v/s epoch\"\n",
    "        if text:\n",
    "            self.trai_title = self.trai_title+\" for different \"+text\n",
    "            self.vali_title = self.vali_title+\" for different \"+text\n",
    "        self.widget = interact(self.display).widget\n",
    "\n",
    "    def display(self):\n",
    "        fig, ax = plt.subplots(1,2,figsize=(12,6),sharex=True,sharey=True)\n",
    "        ax[0].set_ylim(0.01,100)\n",
    "        # Train error:\n",
    "        ax[0].set(xlabel='epoch',ylabel='training error',title=self.trai_title)\n",
    "        for i in range(len(self.trai_err)):\n",
    "            col = {} if not self.labels else {\n",
    "                'c':color(i,len(self.labels)),'label':self.labels[i]}\n",
    "            x = np.arange(1,1+len(self.trai_err[i]))\n",
    "            ax[0].semilogy(x,self.trai_err[i],linewidth=2,**col)\n",
    "        ax[0].grid()\n",
    "        if self.labels: ax[0].legend()\n",
    "        # Validation error\n",
    "        ax[1].set(xlabel='epoch',ylabel='validation error',title=self.vali_title)\n",
    "        for i in range(len(self.vali_err)):\n",
    "            col = {} if not self.labels else {\n",
    "                'c':color(i,len(self.labels)),'label':self.labels[i]}\n",
    "            x = np.arange(1,1+len(self.vali_err[i]))\n",
    "            ax[1].semilogy(x,self.vali_err[i],linewidth=2,**col)\n",
    "        ax[1].grid()\n",
    "        if self.labels: ax[1].legend()\n",
    "        #\n",
    "        plt.show()\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.trai_err.append([])\n",
    "        self.vali_err.append([])\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        vali_loss = logs.get('val_loss')\n",
    "        trai_loss = logs.get('loss')\n",
    "        self.vali_err[-1].append(vali_loss)\n",
    "        self.trai_err[-1].append(trai_loss)\n",
    "        self.widget.update()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5 # Change to 250\n",
    "EXPERIMENTS = 3 # Change to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "callback = PlotErrors(\"experiments\")\n",
    "for i in range(EXPERIMENTS):\n",
    "    model = create_model(activation=\"sigmoid\")\n",
    "    history = model.fit(X_trai_scaled, y_trai, epochs=EPOCHS, verbose=0,\n",
    "        validation_data=(X_vali_scaled, y_vali), callbacks=[callback])\n",
    "    del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "c) Repita el paso anterior, utilizado ’**ReLU**’ como función de activación y compare con lo obtenido en b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "callback = PlotErrors(\"experiments\")\n",
    "for i in range(EXPERIMENTS):\n",
    "    initi = keras.initializers.RandomUniform(minval=-0.01, maxval=0.01)\n",
    "    model = create_model(activation=\"relu\",initializer=initi)\n",
    "    history = model.fit(X_trai_scaled, y_trai, epochs=EPOCHS, verbose=0,\n",
    "        validation_data=(X_vali_scaled, y_vali), callbacks=[callback])\n",
    "    del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO Respuesta**\n",
    "\n",
    "Cabe señalar que se debió utilizar un inicializador lineal con valores pequeños, ya que `kernel_initializer=\"uniform\"` resultó en pérdidas `NaN` y `kernel_initializer=\"zeros\"` resulta en experimentos con resultados iguales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "d) Repita b) y c) variando la tasa de aprendizaje (*learning rate*) en un rango sensible. Comente. Si observara divergencia durante el entrenamiento, determine si esto ocurre para cada repetición del experimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lr = 10\n",
    "learn_rate = np.arange(1,n_lr+1)/(20.0*n_lr)\n",
    "print(learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sigmoid nets\n",
    "callback_sigm = PlotErrors(\"learning rates\",[str(x) for x in learn_rate])\n",
    "for lr in learn_rate:\n",
    "    model = create_model(activation=\"sigmoid\",initializer=\"zeros\",lr=lr) # Notice zeros\n",
    "    history = model.fit(X_trai_scaled, y_trai, epochs=EPOCHS, verbose=0,\n",
    "        validation_data=(X_vali_scaled, y_vali), callbacks=[callback_sigm])\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relu nets\n",
    "callback_relu = PlotErrors(\"learning rates\",[str(x) for x in learn_rate])\n",
    "for lr in learn_rate:\n",
    "    model = create_model(activation=\"relu\",initializer=\"zeros\",lr=lr) # Notice zeros\n",
    "    history = model.fit(X_trai_scaled, y_trai, epochs=EPOCHS, verbose=0,\n",
    "        validation_data=(X_vali_scaled, y_vali), callbacks=[callback_relu])\n",
    "    del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "e) Entrene los modelos considerados en b) y c) usando *progressive decay*. Compare y comente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 0.2\n",
    "n_decays = 10\n",
    "decays = np.logspace(-6,0,n_decays)\n",
    "print(decays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = PlotErrors(\"learning decays\",[str(x) for x in decays])\n",
    "for dec in decays:\n",
    "    model = create_model(activation=\"sigmoid\",initializer=\"zeros\",lr=INIT_LR,decay=dec)\n",
    "    history = model.fit(X_trai_scaled, y_trai, epochs=EPOCHS, verbose=0,\n",
    "        validation_data=(X_vali_scaled, y_vali), callbacks=[callback])\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = PlotErrors(\"learning decays\",[str(x) for x in decays])\n",
    "for dec in decays:\n",
    "    model = create_model(activation=\"relu\",initializer=\"zeros\",lr=INIT_LR,decay=dec)\n",
    "    history = model.fit(X_trai_scaled, y_trai, epochs=EPOCHS, verbose=0,\n",
    "        validation_data=(X_vali_scaled, y_vali), callbacks=[callback])\n",
    "    del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo con [esta respuesta](https://stats.stackexchange.com/a/211340), la tasa de aprendizaje dado un *decay* $D$ es:\n",
    "$$\n",
    "L_t = L_0 \\, \\frac{1}{1 +  t \\cdot D}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "f) Entrene los modelos considerados en b) y c) utilizando SGD en mini-*batches*. Experimente con diferentes tamaños del *batch*. Comente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = 21\n",
    "batch_sizes = np.round(np.linspace(1,X_train_scaled.shape[0],n_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = PlotErrors(\"batch sizes\",[str(x) for x in batch_sizes])\n",
    "for bs in batch_sizes:\n",
    "    model = create_model(activation=\"sigmoid\",initializer=\"zeros\")\n",
    "    history = model.fit(X_trai_scaled, y_trai, epochs=EPOCHS, verbose=0,\n",
    "        validation_data=(X_vali_scaled, y_vali), callbacks=[callback],\n",
    "        batch_size=bs)\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = PlotErrors(\"batch sizes\",[str(x) for x in batch_sizes])\n",
    "for bs in batch_sizes:\n",
    "    model = create_model(activation=\"relu\",initializer=\"zeros\")\n",
    "    history = model.fit(X_trai_scaled, y_trai, epochs=EPOCHS, verbose=0,\n",
    "        validation_data=(X_vali_scaled, y_vali), callbacks=[callback],\n",
    "        batch_size=bs)\n",
    "    del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "g) Entrene los modelos obtenidos en b) y c) utilizando estrategias modernas para adaptar la tasa de aprendizaje. Compare los desempeños de adagrad, adadelta, RMSprop y adam. ¿Se observa en algún caso un mejor resultado final? ¿Se observa en algún caso una mayor velocidad de convergencia sobre el dataset de entrenamiento? ¿Sobre el dataset de validación?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam, RMSprop, Adagrad, Adadelta\n",
    "moptimizer = Adagrad(lr=0.01)\n",
    "model.compile(optimizer=moptimizer)\n",
    "model.fit(X_train_scaled,y_train,batch_size=bs,epochs=250,validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "h) Entrene los modelos obtenidos en b) y c) utilizando regularizadores $l_1$ y $l_2$ (*weight decay*). Compare los desempeños de prueba obtenidos antes y después de regularizar. Experimente con distintos valores del parámetro de regularización y comente. Además evalúe el efecto de regularizar solo la primera capa *vs* la segunda, comente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "...#la regularization se debe incorporar a cada capa separadamente\n",
    "idim=X_train_scaled.shape[1]\n",
    "model.add(Dense(256,input_dim=idim,kernel_initializer='uniform',W_regularizer=l2(0.01)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1, kernel_initializer='uniform',W_regularizer=l2(0.01)))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "i) Entrene los modelos obtenidos en b) y c) utilizando *Dropout*. Compare los desempeños de prueba obtenidos antes y después de regularizar. Experimente con distintos valores del parámetro de regularización y comente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "model = Sequential()\n",
    "...\n",
    "model.add(Dense(256,kernel_initializer='uniform'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "j) Fijando todos los demás hiper-parámetros del modelo definido en b) y en c), utilice validación cruzada con un número de *folds* igual a *K* = 5 y *K*=10 para determinar el mejor valor correspondiente a un parámetro que usted elija (tasa de aprendizaje, número de neuronas, parámetro de regularización, etc) ¿El mejor parámetro para la red con sigmoidal es distinto que para ReLU? ¿Porqué sucede? Además mida el error real del modelo sobre el conjunto de pruebas, compare y concluya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "84-hf1CuNqhZ"
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "Xm = X_train_scaled.values\n",
    "ym = y_train\n",
    "kfold = cross_validation.KFold(len(Xm), 10)\n",
    "cvscores = []\n",
    "for i, (train, val) in enumerate(kfold):\n",
    "    ...# create model\n",
    "    model = #model with hiperparam\n",
    "    ...# Compile model\n",
    "    model.compile(optimizer=,loss='mean_squared_error')\n",
    "    ...# Fit the model\n",
    "    model.fit(Xm[train], ym[train], epochs=250)\n",
    "    ...# evaluate the model\n",
    "    scores = model.evaluate(Xm[val], ym[val])\n",
    "    cvscores.append(scores)\n",
    "mse_cv = np.mean(cvscores)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Enunciado.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
